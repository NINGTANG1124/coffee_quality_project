# -*- coding: utf-8 -*-
"""Coffee_rating_project analysis

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GztWwqy7UXhuRoPMeDiZ5kCMYC6FrNnb
"""

#from google.colab import drive; drive.mount('/content/drive')

import pandas as pd

# Rread file
#data = pd.read_csv('/content/drive/MyDrive/coffee_quality_project/coffee_ratings.csv')
data = pd.read_csv('data/coffee_ratings.csv')

# Check for missing values
print("Missing value statistics：")
print(data.isnull().sum())

# Delete columns with excessive missing values（>50%)
missing_percentage = data.isnull().mean() * 100
columns_to_drop = missing_percentage[missing_percentage > 50].index
data = data.drop(columns=columns_to_drop)
print(f'Deleted the following (more than 50% missing values): {list(columns_to_drop)}')

# Fill missing values
data['total_cup_points'].fillna(data['total_cup_points'].median(), inplace=True)
data['country_of_origin'].fillna(data['country_of_origin'].mode()[0], inplace=True)
data['species'].fillna(data['species'].mode()[0], inplace=True)

# Deleting Exceptions
# Remove outliers with scores below 50 or above 100
data = data[(data['total_cup_points'] >= 50) & (data['total_cup_points'] <= 100)]
# Remove unusual samples with negative elevation values
data = data[data['altitude_mean_meters'] > 0]

# Delete irrelevant columns
columns_to_remove = ['lot_number', 'ico_number', 'certification_body', 'expiration']
data = data.drop(columns=columns_to_remove, errors='ignore')

# Check cleaned data
print("cleaned data：")
print(data.head())
print(data.info())
print(data.describe())

# Data Visualisation
import seaborn as sns
import matplotlib.pyplot as plt

# Histogram of rating distribution
plt.figure(figsize=(10, 6))
sns.histplot(data['total_cup_points'], bins=50, kde=True, color='blue')
plt.title("Rating Distribution")
plt.xlabel("Total Cup Points")
plt.ylabel("Sample Count")
plt.xlim(0, 100)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()

data['species'] = data['species'].str.strip().str.capitalize()
# Check coffee species
unique_species = data['species'].unique()
species_count = data['species'].nunique()

print("Coffee species include：", unique_species)
print("Total number of coffee species is：", species_count)

# Distribution of ratings by species
species_list = data['species'].unique()

plt.figure(figsize=(12, 8))
for species in species_list:
    subset = data[data['species'] == species]
    sns.histplot(subset['total_cup_points'], kde=True, label=species, bins=30, alpha=0.5)

plt.title('Total Cup Points Distribution by Species', fontsize=16)
plt.xlabel('Total Cup Points', fontsize=12)
plt.ylabel('Sample Count', fontsize=12)
plt.legend(title='Species')
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

# 1. Scatterplot of ratings and altitude
plt.figure(figsize=(10, 6))
sns.scatterplot(x='altitude_mean_meters', y='total_cup_points', data=data, alpha=0.6, color='blue')
plt.title('Scatter Plot: Total Cup Points vs Altitude', fontsize=16)
plt.xlabel('Mean Altitude (meters)', fontsize=12)
plt.ylabel('Total Cup Points', fontsize=12)
plt.grid()
plt.show()

# 2. Regression analysis
plt.figure(figsize=(10, 6))
sns.regplot(x='altitude_mean_meters', y='total_cup_points', data=data, scatter_kws={'alpha': 0.5}, line_kws={'color': 'red'})
plt.title('Regression: Total Cup Points vs Altitude', fontsize=16)
plt.xlabel('Mean Altitude (meters)', fontsize=12)
plt.ylabel('Total Cup Points', fontsize=12)
plt.grid()
plt.show()

# Check unique values for country names
print("Unique countries in the data:")
print(data['country_of_origin'].unique())

# Standardised country names
data['country_of_origin'] = data['country_of_origin'].str.strip().str.title()

import plotly.express as px

# Average of ratings by country
country_ratings = data.groupby('country_of_origin', as_index=False)['total_cup_points'].mean()
country_ratings.columns = ['country', 'avg_rating']

print(country_ratings.head())

# Interactive map
fig = px.choropleth(
    country_ratings,
    locations="country",
    locationmode="country names",
    color="avg_rating",
    title="Average Coffee Rating by Country",
    color_continuous_scale="YlGnBu",
    labels={'avg_rating': 'Average Rating'}
)

fig.show()

# Calculate correlation matrix
correlation_matrix = data[['total_cup_points', 'flavor', 'acidity']].corr()

# Heat mapping of flavour and acidity
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Heatmap: Ratings, Flavor, and Acidity', fontsize=16)
plt.show()